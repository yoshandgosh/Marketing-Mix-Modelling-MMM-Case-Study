# Install meridian: from PyPI @ latest release
!pip install --upgrade google-meridian[colab]

!pip install --upgrade google-meridian[colab]
from google.colab import drive
drive.mount('/content/drive')
# @title
import pandas as pd

fixed_path = #add datasheet file path
df = pd.read_csv(fixed_path)
coord_to_columns = load.CoordToColumns(
    time='week_start',
    geo=None,   # if you don’t have geo split, just leave None
    controls=[],  # e.g., competitor sales or macro controls if you have them
    population=None,  # if you don’t have population data
    kpi='event_registrants',
    # revenue_per_kpi=None,  # unless you can assign $ per registrant
    media=[
        'content_s',
        'display_s',
        'ooh_static_s',
        'search_s',
        'social_s',
        'video_s',
    ],
    media_spend=[
        'content_s',
        'display_s',
        'ooh_static_s',
        'search_s',
        'social_s',
        'video_s',
    ],
    organic_media=[
        'facebook_organic_impressions',
    ],
    non_media_treatments=[
        'public_holiday_flag',
        'school_holiday_flag',
    ],
)

loader = load.CsvDataLoader(
    csv_path=fixed_path,
    kpi_type="non_revenue",
    coord_to_columns=coord_to_columns,
    media_to_channel=correct_media_to_channel,
    media_spend_to_channel=correct_media_spend_to_channel,
)

data = loader.load()
roi_mu = 0.2     # Mu for ROI prior for each media channel. (Mean)
roi_sigma = 0.9  # Sigma for ROI prior for each media channel. (Standard Deviation)
prior = prior_distribution.PriorDistribution(
    roi_m=tfp.distributions.LogNormal(roi_mu, roi_sigma, name=constants.ROI_M)
)
model_spec = spec.ModelSpec(prior=prior)

mmm = model.Meridian(input_data=data, model_spec=model_spec)
#%%time

mmm.sample_prior(500)
#It tells the function to generate 500 samples from the prior distribution.x



from tqdm.notebook import tqdm  # Import tqdm for Jupyter Notebook
import time

# ... (rest of your imports and code) ...

with tqdm(total=5*1000, desc="Training Progress") as pbar:  # Total iterations
    def update_progress(current_iteration, total_iterations):
        pbar.update(current_iteration)  # Update the progress bar

    # Remove progress_callback from the sample_posterior call
    mmm.sample_posterior(
        n_chains=5,
        n_adapt=500,
        n_burnin=500,
        n_keep=1000,
        parallel_iterations=100,
        # progress_callback=update_progress  # Remove this line
    )
    # Manually update progress bar after sampling
    pbar.update(5 * 1000)

#n_chains: Markov Chain Monte Carlo (MCMC) indipendent chains
#n_adapt: number of initial samples used to tune the sampling algorithm for better performance
#n_burnin: number of initial samples from each chain that are discarded
#n_keep: number of samples to keep from each chain after the burn-in phase. These samples represent the posterior distribution of the model parameters and are used for inference.

model_diagnostics = visualizer.ModelDiagnostics(mmm)
model_diagnostics.plot_rhat_boxplot()

mm_summarizer = summarizer.Summarizer(mmm)

#save output
from google.colab import drive
drive.mount('/content/drive')

filepath = '#add file path
start_date = '2023-01-02'
end_date = '2024-12-30'
mmm_summarizer.output_model_results_summary('mmm_summary_output.html', filepath, start_date, end_date)
#preview 2 pager
IPython.display.HTML(filename='#filename')


%%time
budget_optimizer = optimizer.BudgetOptimizer(mmm)
optimization_results = budget_optimizer.optimize(use_kpi=True)



